\chapter{Methods: ``\hotspice'' simulator for ASI}\label{ch:Hotspice}
% \glijbaantje{It's not a bug, it's a feature.}{Someone}

\begin{adjustwidth}{2em}{2em} % TODO END: update once published.
    \begin{center}
        \textbf{Material from this chapter has also been published in:} \\
    \end{center}
    \vspace{1em}
    \begin{adjustwidth}{0em}{3em}
	    \begin{itemize}
	    	\item[\cite{MAES-24}] J.~Maes, D.~De~Gusem, I.~Lateur, J.~Leliaert, A.~Kurenkov, and B.~Van~Waeyenberge.
	    	\newblock The design, verification, and applications of Hotspice: a Monte Carlo simulator for artificial spin ice.
	    	\newblock \emph{ArXiV}, arXiv:\penalty0 2409.05580, 2024.
	    \end{itemize}
    \end{adjustwidth}
    \vspace{0.5em}
    \begin{center}
        \centering\rule{0.7\linewidth}{0.4pt}
    \end{center}
    \vspace{.5em}
    \begin{center}
    	The \hotspice simulator discussed in this chapter\\
    	is open-source and available on \href{https://github.com/bvwaeyen/Hotspice}{GitHub}. \\
    \end{center}
    %\vspace{0.5em}
    \begin{center}
    \centering\rule{0.7\linewidth}{0.4pt}
    \end{center}
    \vspace{1em}
\end{adjustwidth}

To assess the potential of \xref{Reservoir Computing} in (perpendicular-anisotropy) \xref{Artificial Spin Ice}, as is the main topic of this thesis, a simulation framework is needed that allows efficient exploration of the impact that various system parameters and input methods have on the reservoir performance. \\\par

Nanomagnetic systems are often simulated using micromagnetic codes, such as the finite-difference-based \mumax~\cite{mumax3} and \oommf~\cite{OOMMF} or the finite-element-based \nmag~\cite{Nmag}, which capture the magnetization dynamics of individual nanomagnets in great detail. \par
However, the time between successive switches of a nanomagnet is not necessarily similar to the timescale of micromagnetics.
Furthermore, determining RC metrics requires applying many input cycles -- on the order of 100 for the task-agnostic metrics -- to get a statistically valid result.
In this timeframe, many switches occur.
When the simulated time extends beyond several microseconds, as is typically the case, simulating even a modest number of magnets -- on the order of several dozen -- becomes computationally unfeasible~\cite{leo2021chiral}. \\\par

To address these limitations, specialized ASI simulation tools have been developed.
An example of this is the flatspin simulator~\cite{flatspin}, which implements deterministic spin flipping via a Stoner-Wohlfarth model~\cite{StonerWohlfarth2008}.
Using such higher-level approximations enables the study of collective behaviour in much larger systems and over far longer timescales than is feasible with micromagnetic codes, though at the cost of no longer simulating the internal magnetization structure of individual nanomagnets in detail.
Additionally, Monte Carlo methods are often used to simulate spin ices, including ASI, but these are typically specialized to a select few lattice geometries and often only account for nearest-neighbour interactions, whose strength is often arbitrarily set or calculated separately using micromagnetic codes.~\cite{MeltingASI,sklenar2019field,gilbert2014emergent,zhang2013crystallites} \\\par % REFS: 'gilbert2014emergent': MC sims based on a vertex model and interacting magnetic charges. 'zhang2013crystallites': uses monopoles and NN couplings to model kagome ASI with Metropolis and loop update. 'moller2006artificial': bit broader using dipolar interaction, though seemingly still only for nearest neighbors. 'mengotti2011kagome' use a full dipole model with Ewald summation for PBC. 'lou2023competing': dipole model for half-occupation IP Ising. 'sendetskyi2019continuous': dipole model for square ASI. 'EngineeringRelaxationComputation': KMC on dipole model, seemingly for square arrays. 'sklenar2019field': NN interactions calculated by mumax on quadrupole lattice. 'MeltingASI': 16-vertex ice model

Our goal was to blend these two approaches, resulting in \hotspice: a versatile Monte Carlo simulator meant to capture ASI physics with minimal arbitrary parameters, allowing various lattice configurations to be evaluated. \par
This software approximates each single-domain nanomagnet as a single Ising spin, associating energies with the various ASI states by accounting for the magnetostatic interaction between all magnets.
\hotspice supports both in-plane (IP) and out-of-plane (OOP) ASI, which may contain thousands of magnets. Simulations can span arbitrary timescales, as determined by the switching time of magnets in the system. \\\par

In this chapter, we discuss several model variants that have been implemented, and assess their accuracy in simulating the behaviour of ASI.
These variants differ in their calculation of the magnetostatic interactions, the use of symmetric versus asymmetric energy barriers, and their choice of update algorithm. \\\par

\section{Model}
In single-domain IP nanomagnets, the magnetisation prefers to align along the fixed easy axis of the geometry, while for OOP magnets a strong interfacial anisotropy causes a preferential orientation along the $z$-axis.
Either way, for simulations it is natural to use an Ising-like approximation for such single-domain magnets, where the position $\vc{r}_i$, axis $\vc{u}_i$, and size of the magnetic moment\footnote{
	The size of the magnetic moment $\mu_i$ corresponds to the total ground state magnetic moment $\abs{\int_{\Omega_i} \vc{M}(\vc{r})d\vc{r}}$, with $\Omega_i$ the shape of magnet $i$ and $\vc{M}(\vc{r})$ its magnetisation in the twofold degenerate ground state. Due to edge relaxation effects, this value is slightly smaller than $M_\mathrm{sat} V_i$.
} $\mu_i$ of each magnet $i$ are fixed, allowing the magnets to only switch between the `up' ($\uparrow$) and `down' ($\downarrow$) states.
Thus, the total magnetic moment vector of magnet $i$ can be expressed as
\begin{equation}
	\vc{\mu}_i = s_i \mu_i \vc{u}_i \mathrm{,}
\end{equation}
where $s_i = \pm 1$ and $\abs{\vc{u}_i} = 1$. \par
The switching rate between these two states is determined by the temperature $T$ and the effective energy barrier $\EBtilde$ separating them.
%A canonical ensemble is used where magnets are considered in contact with a heat bath of temperature $T_i$. % TODO: mention this or not?
For an isolated nanomagnet, the energy barrier $\EB = K_\mathrm{u} V$\footnote{
	This is valid for switching by coherent rotation. Similar to the calculation of $\mu$, edge relaxation effects may cause the effective volume to be slightly smaller.
} originates from its uniaxial shape anisotropy $K_\mathrm{u}$.
Interactions with other magnets or external fields modify the energy landscape, leading to an effective barrier $\EBtilde$, which we will denote with a tilde.~\cite{leo2021chiral}
Each magnet can have a unique magnetic moment size $\mu_i$, temperature $T_i$ and energy barrier $E_{\mathrm{B},i}$.
This enables, for instance, modelling some of the disorder due to lithographic variations by assigning a different shape anisotropy to each magnet, typically sampled from a Gaussian distribution with mean $\EB$ and standard deviation $\sigma(\EB)$. \\\par

Due to the periodic nature of many ASI lattices, \hotspice chooses to perform the simulation on a rectilinear grid, the benefits and details of which will be discussed in~\cref{sec:2:Implementation}.
Each grid point may or may not contain a magnet, and the magnets must either all be of the IP type, or all OOP.
Even though this implementation does not allow complete freedom in the placement of magnets, many popular ASI lattices can be constructed in this manner. \par

\xfig[1.0]{2_Hotspice/ASIs.pdf}{
	\label{fig:2:ASIs}Predefined artificial spin ice (ASI) lattices available in \hotspice. The unit cell of each lattice is delineated by a central dark grey rectangle. The red indicator defines the lattice parameter $a$. In the Ising approximation, the magnetization of in-plane magnets (top) aligns along the major axis of the depicted ellipses. Out-of-plane magnets (bottom) are illustrated as circles.
}

\cref{fig:2:ASIs} showcases the 12 lattices that \hotspice provides out-of-the-box. The pinwheel lattices (a) and (b) are equal to the square lattices (c) and (d), respectively, but with each magnet individually rotated by \ang{45}. Both lattices have two variants (diamond/lucky-knot and closed/open), related by a global \ang{45} rotation of the entire lattice. This gives rise to different boundaries due to the Cartesian character of the underlying grid, which may alter the dynamics of the ASI. Furthermore, the unit cell for lucky-knot pinwheel and open square is more compact, resulting in faster simulation, while diamond pinwheel and closed square are more popular in literature and were therefore implemented separately. \par % TODO: more popular in literature? Examples where these are used?
The remaining four IP and four OOP lattices are also related: the magnets in the OOP lattices (i)-(l) are positioned at the vertices where magnets meet in their respective IP counterparts (e)-(h). \\\par


\section{Energy calculation}
\subsection{Energy terms}
Three energy contributions have been implemented in \hotspice, supporting both open and periodic boundary conditions (PBC).\footnote{
	Users can implement more energy contributions by inheriting from the \python{hotspice.Energy} class and implementing the \python{abstractmethod}s, taking care to correctly account for open or periodic BC when necessary.
}
\begin{enumerate}
	\item The \textit{magnetostatic interaction energy} between magnets $i$ and $j$
	\begin{equation}
		E_{\mathrm{MS},i,j} = \frac{\mu_0}{4 \pi} \ab(\frac{\vc{\mu}_i \bcdot \vc{\mu}_j}{\abs{\vc{r}_{ij}}^3} - \frac{3(\vc{\mu}_i \bcdot \vc{r}_{ij}) (\vc{\mu}_j \bcdot \vc{r}_{ij})}{\abs{\vc{r}_{ij}}^5}) \mathrm{,}
		\label{eq:E_MS}
	\end{equation}
	with $\mu_0$ the vacuum permeability and $\vc{r}_{ij} = \vc{r}_i - \vc{r}_j$ the vector connecting the two magnetic dipoles $\vc{\mu}_i$ and $\vc{\mu}_j$. \par
	This is the main interaction dictating how nanomagnets influence each other, causing the typical properties of the various ASI lattices, e.g. superferromagnetism in the pinwheel lattice~\cite{li2018pinwheel}.
	Because of its importance, this is the only interaction \hotspice considers by default when an ASI is created.
	Any other energy contributions must explicitly be added to an ASI; see \cref{sec:2:API_energies}.
	This avoids wasting calculations on energies not relevant to the simulation.
	
	\item The \textit{Zeeman energy} of an external field $\vc{B}_\mathrm{ext}$ interacting with magnet $i$
	\begin{equation}
		E_{\mathrm{Z},i} = -\vc{\mu}_i \bcdot \vc{B}_\mathrm{ext} \mathrm{,} \label{eq:E_Z}
	\end{equation}
	where $\vc{B}_\mathrm{ext}$ can be set for each magnet individually. \par
	This energy contribution provides a means for the outside world to interact with the system, and is therefore indispensable when we will be investigating reservoir computing later on.
	Even if input is provided through other means than an external field, this energy contribution can often still be used by considering an effective field instead.
	
	\item The \textit{exchange coupling energy} between nearest neighbours (NN) $i$ and $j$
	\begin{equation}
		E_{\mathrm{exch},i,j} = J \frac{\vc{\mu}_i \bcdot \vc{\mu}_j}{\mu_i \mu_j} \mathrm{,} \label{eq:Eexch}
	\end{equation}
	with $J$ the exchange coupling constant, which is constant throughout the ASI. \par
	This interaction is rarely present in ASI, but can for example be relevant in interconnected ASI -- whether by design or due to limited lithographic accuracy.
	We will encounter an example of the latter in \cref{sec:3:OOP:MFM}.
\end{enumerate}

The combined \textit{interaction energy} $E_i$ of a single magnet $i$ with its environment is then given by
\begin{equation}
	E_i = E_{\mathrm{Z},i} + \sum_j E_{\mathrm{MS},i,j} + \sum_{j \in \mathcal{N}_i} E_{\mathrm{exch},i,j} \mathrm{,}
	\label{eq:E}
\end{equation}
where $\mathcal{N}_i$ is the collection of nearest neighbours of magnet $i$.
Which magnets are included in this collection depends on the ASI lattice and which site of the unit cell magnet $i$ is in, and can be defined separately for each ASI lattice. \\\par
Note that all terms in \cref{eq:E} simply change sign when magnet $i$ switches ($\vc{\mu}_i \rightarrow -\vc{\mu}_i$).
The magnetostatic self-energy is not present in \cref{eq:E} because it only contributes a constant offset and does not change when the magnet switches.
As such, $E_i$ represents the total interaction energy of a magnet with its `neighbours',\footnote{
	In this context, a `neighbour' of a magnet can be interpreted more broadly as all magnets it interacts with through a particular energy contribution. For example, the magnetostatic interaction considers all magnets to be `neigbours', unless the user has explicitly set a maximum interaction distance.
} and therefore the change in energy of the whole ASI when magnet $i$ switches is simply $\Delta E_{i,1\rightarrow2} = -2 E_i$.
This is called the \textit{switching energy}, and we will later see (\cref{sec:2:Dynamics}) that it takes a central role in the algorithms used for simulating system dynamics.
It is therefore very advantageous to have such a simple method of calculating the switching energy. \par
When the simulation is initialized, the energy contributions are calculated for all magnets.
Each magnet therefore has a value for each of the terms in \cref{eq:E} stored in memory.
Whenever a magnet switches, the energies of its `neighbours' are updated appropriately, which constitutes a major part of the calculation effort required for every step in the simulation.

\subsection{Finite-size correction for magnetostatic energy}
\subsubsection{Second-order correction for dipoles}
\subsubsection{Dumbbell model}
\subsubsection{Comparison}
\subsection{Effective energy barrier}
\subsubsection{Intrinsic barrier from shape anisotropy}
\subsubsection{Mean-barrier approximation} % and relevant choices with discontinuities
\subsubsection{Asymmetric barrier}
\subsubsection{Exact solution} % OOP only

\section{Dynamics}\label{sec:2:Dynamics}
\subsection{N\'eel relaxation: temporal evolution}
\subsection{Metropolis-Hastings: sampling equilibrium states}
% TODO: decide whether to talk about nomenclature details etc. here, or in the introduction.
\subsection{Other Monte Carlo algorithms} % Not implemented, explain why Wolff could be useful but why it's not in Hotspice

\section{Implementation}\label{sec:2:Implementation}
Now that the physics underlying the simulator have been extensively discussed, we turn our attention to the implementation in software. \par
First, we discuss why we chose to implement the ASI on an underlying rectilinear grid, and explain how the \textit{`kernel'} -- the lookup table for the magnetostatic interaction -- was implemented.
We then take a look at the performance of \hotspice and how it has improved since its initial version due to improvements to the kernel.
One particular performance-enhancing feature is examined in more detail: the possibility to select multiple magnets at once in the Metropolis-Hastings algorithm.
Finally, we briefly discuss the structure of the package and the functionality included in the various submodules, and finish with a small discussion of things that could have been done better.

\subsection{Grid}
\hotspice{} represents an ASI as a rectilinear grid of non-uniform unit cells, with magnets positioned at selected grid points.
This choice was made based on a trade-off; calculation efficiency against the freedom to place magnets arbitrarily.
We opted to prioritise efficiency and accept the geometrical restriction, as most ASI research focuses on periodic lattices.
Despite the seemingly restrictive nature of the rectilinear grid,~\cref{fig:2:ASIs} illustrates its versatility in forming various periodic lattices, with only the Cairo lattices requiring grid non-uniformity.
As a bonus, real-time visualisation is simple and efficient for a rectilinear grid, as the underlying matrix can directly be cast to a pixel image. \par
By leveraging the unit cell concept in periodic lattices and the efficient indexation of a rectilinear grid in computer memory, several aspects of the calculation can be performed more efficiently than for free-form ASI. The unit cell of each lattice in~\cref{fig:2:ASIs} is depicted as a grey rectangle. Although non-rectilinear unit cells with fewer magnets could be identified for some lattices, \hotspice{} does not consider these to reduce complexity and to maintain a clear connection to the underlying rectilinear grid of the ASI implementation.

\subsection{Kernels}\label{sec:2:Kernels}
The kernel serves to reduce the amount of calculations required for every switch, so there is usually a trade-off between the initialisation time and runtime when simulating dynamics.
\subsubsection{Perpendicular kernel} % If not yet explained in detail earlier, talk about the perpendicular kernel etc. here
\subsubsection{Numerical error with cut-off kernel} % TODO
A performance improvement presents itself by cutting off the magnetostatic kernel at a certain distance.
Due to the underlying grid, the most natural way of achieving this is to simply reduce the size of the kernel from $2L-1 \times 2L-1$ to a smaller $2K-1 \times 2K-1$ central region. \par % Note that the size has to remain odd for the convolution to still place the magnet in the center.
However, this will result in inaccurate interaction energies being stored.
When multiple magnets switch, this error will accumulate.
Luckily, the error introduced in this manner is bounded from above: whenever a magnet switches back, the error its original switch introduced is cancelled (barring some remaining floating-point error).

\subsection{Performance} % Several factors impacting performance, explain by using that one graph
% TODO: update this introductory text, because now this section comes after the explanation of the kernels.
The performance of \hotspice has been improved throughout development in various ways.
Calculation on the GPU was made possible early on and the efficiency of updating the magnetostatic interaction was improved drastically.
The number of magnets in the ASI has a major impact on performance, and often forms the determining factor as to whether calculation on the GPU rather than CPU will result in a faster simulation. \par
We start with a summarizing chronological table of these various improvements, and explain each step in more detail in the following paragraphs.
Two tables are shown:~\cref{tab:2:perf_init} for the initialisation time, and~\cref{tab:2:perf_switch} for the time it takes to perform 5000 switches using the N\'eel update algorithm.
During initialisation, the magnetostatic kernel is constructed, after which the starting energy $E_i$ of all magnets is calculated.
In the tables, only the last 3 rows use the kernel as it was explained in~\cref{sec:2:Kernels}; the other rows use less efficient kernels as explained below. \par % Can't really call it a "lookup table" if it is being convolved etc., right?
This test was benchmarked on an NVIDIA GeForce RTX 3080 Mobile GPU and an 11th Gen Intel\textregistered{} Core\texttrademark{} i7-11800H @ 2.30GHz. Simulation times displayed serve an illustrative purpose: absolute values on other hardware may vary significantly, though the general trends within the tables should remain similar.

% Q: should we use L or N=L²? I would prefer L because at some point we talk about 2D indexation, so L makes it clearer that we have a 2D system.
\xtable[tab:2:perf_init]{\textbf{Initialisation time} for various simulation sizes $L$ (i.e. $L \times L = N$ magnets). `Mem' indicates excessive memory consumption, `?' indicates a prohibitively long simulation time ($\gtrsim \SI{1000}{\second}$).}{
	\begin{tabular}{r|c|c|c|c|c|c}
		Simulation size $L$ & 50 & 100 & 150 & 200 & 400 & 1000 \\
		\hline \hline
		CPU | \makecell{Full interaction kernel} & 0.5s & 6.8s & 34.0s & Mem & Mem & Mem \\
		\hline
		GPU | \makecell{Full interaction kernel} & 2.2s & 5.4s & 11.9s & Mem & Mem & Mem \\
		\hline
		GPU | \makecell{Recalculate after each switch} & 1.0s & 3.4s & 7.6s & 14.5s & 91.6s & ? \\
		\hline
		GPU | \makecell{Precalculated unitcell-kernel} & 2.4s & 4.6s & 9.7s & 16.3s & 66.2s & 730.4s \\
		\hline \hline
		GPU | \makecell{Final version\\(convolution initialization)} & 1.0s & 1.0s & 1.0s & 1.0s & 1.6s & 23.9s \\
		\hline
		CPU | \makecell{Final version\\(convolution initialization)} & 0.014s & 0.2s & 1.0s & 3.2s & 53.1s & ? \\
		\hline
	\end{tabular}
}

\xtable[tab:2:perf_switch]{\textbf{Time for 5000 switches} using the N\'eel algorithm, for various simulation sizes $L$ (i.e. $L \times L = N$ magnets). `Mem' indicates excessive memory consumption, `?' indicates a prohibitively long simulation time ($\gtrsim \SI{1000}{\second}$).}{
	\begin{tabular}{r|c|c|c|c|c|c}
		Simulation size $L$ & 50 & 100 & 150 & 200 & 400 & 1000 \\
		\hline \hline
		CPU | \makecell{Full interaction kernel} & 9.4s & 217.6s & ? & Mem & Mem & Mem \\
		\hline
		GPU | \makecell{Full interaction kernel} & 5.0s & 13.6s & 51.8s & Mem & Mem & Mem \\
		\hline
		GPU | \makecell{Recalculate after each switch} & 7.1s & 7.2s & 8.2s & 9.0s & 13.0s & ? \\
		\hline
		GPU | \makecell{Precalculated unitcell-kernel} & 7.8s & 7.9s & 8.3s & 8.9s & 11.8s & 36.9s \\
		\hline \hline
		GPU | \makecell{Final version\\(2D indexation)} & 6.8s & 7.0s & 7.2s & 7.6s & 10.2s & 35.9s \\
		\hline
		CPU | \makecell{Final version\\(2D indexation)} & 0.56s & 1.3s & 2.5s & 4.3s & 41s & ? \\
		\hline
	\end{tabular}
}

\paragraph{From CPU to GPU}
Originally, \hotspice performed all calculations on the CPU. % TODO: explain CPU/GPU briefly? Or elsewhere?
This caused the simulation time to rise dramatically as the system size grew (e.g. first row in \cref{tab:2:perf_switch}).
For early versions of \hotspice with an unoptimized kernel, this made it impractical to simulate systems larger than $50 \times 50$ magnets.
By simply switching to GPU-based calculations using the \python{CuPy} library (second row), this upper limit was increased significantly. The limiting factor instead became memory consumption of the unoptimized kernel. \par
Do note, however, that for small systems the GPU performs worse than the CPU.
This remains true independent of the kernel implementation.
GPUs are optimized for parallel processing, and therefore reach a bottleneck when the simulation takes on a more sequential nature~\cite{owens2008gpu}.
Simulating a single switch requires several distinct operations that do not lend themselves to parallelisation.
When operating on small arrays, this means relatively fewer parallel calculations can be performed, thereby increasing the importance of being able to perform distinct mathematical operations in quick succession.
The CPU excels at the latter. % TODO: references for GPU performance and operation


\paragraph{Kernel improvements}
The first two rows `\textit{Full interaction kernel}' use the original method, where the kernel was far more naïve: it was simply an $N \times N$ matrix which stored the dipolar interaction between each pair of magnets.
The initialisation time on CPU (first row in~\cref{tab:2:perf_init}) bears witness to this, as it is $\propto L^4 = N^2$.
This was obviously a huge waste of memory, as evidenced by the fact that a system as small as $200 \times 200$ required a kernel larger than the \SI{8}{\giga\byte} available memory.
Not only that, but for sparse ASI with empty cells there were many zero-elements in this matrix.
In short, this was unsustainable and had to be improved upon. \\\par
In the third row `\textit{Recalculate after each switch}', an attempt was made to not use a kernel at all. Instead, for every switch, the interaction energy of the switching magnet with all other magnets is calculated on-the-fly. This clearly gets rid of the memory issue and yields a surprisingly fast simulation, though now the initialisation becomes the bottleneck. This is because the initialisation was done by iterating over all magnets and adding the interaction energies sequentially. \\\par
As such, there were still two clear improvements to be made. On the one hand, using a kernel as described earlier in~\cref{sec:2:Kernels}, and on the other hand performing a convolution to determine the initial interaction energies. The former is solved in the fourth row `\textit{Precalculated unitcell-kernel}', the latter in the final two rows `\textit{Final version}' where once again the CPU and GPU are compared. %The reason such a convolution was not implemented initially, is because it requires writing a custom function for each energy component.
% TODO: incorporate the following sentences in the preceding text
Not shown in the tables, however, is that the usage of kernels improves the performance for multi-switching in Metropolis-Hastings significantly as compared to recalculating the required values for each magnet that switches.
Another small improvement in the final version is using 2D indices rather than 1D arrays, which improved performance by about \SI{15}{\percent}.

\paragraph{Final performance}
After these various improvements, the upper limit for feasible calculation time was increased to $L \approx 1000$ for GPU and $L \approx 400$ for CPU. As can be noted by comparing the last two rows of \cref{tab:2:perf_switch}, GPU outperforms CPU for $L \gtrapprox 300$.
The same goes for the initialisation time (\cref{tab:2:perf_init}), where this transition already occurs at $L > 150$.
However, when using the Metropolis-Hastings algorithm (not shown in the tables), enabling multi-switching allows the GPU to maintain the advantage for systems as small as $L \gtrapprox 70$, because the associated convolution can be performed very efficiently on GPU.

\paragraph{RNG}
Another factor which may contribute to the performance is the Random Number Generator (RNG).
Both update algorithms rely on generating a large amount of random numbers to select the next magnet(s) to switch. % TODO: talk a bit about XORWOW etc. and how it actually doesn't really impact performance

\subsection{Multi-switching in Metropolis-Hastings} % TODO: I already talk about multi-switching in the performance section, should we put this earlier?
\subsubsection{Minimal distance between sampled magnets} % Derive equation
\subsubsection{Selection algorithms}
\paragraph{Poisson disc}
\paragraph{Grid-select}
\paragraph{Hybrid grid-poisson}

\subsection{Package structure} % Structure of Hotspice, explain all modules (core, ASI, energies, (config? with GPU)...)
Hotspice is written as a Python 3.10 package and can perform simulations on either the CPU or GPU.
The optimal hardware choice depends on the size of the ASI and the update scheme used.
By default, \hotspice runs on the CPU using the popular NumPy and SciPy libraries.
For GPU-accelerated array manipulation, the CuPy v11.4~\cite{CuPy} library is used, but this is an optional dependency. \par
\paragraph{\python{hotspice.config}: GPU/CPU choice}
By default, \hotspice runs on the CPU. To run on the GPU, the environment variable \python{HOTSPICE_USE_GPU} must be set to \python{"true"} before the the \hotspice package is loaded in a Python script with \python{import hotspice}. It is not possible to switch between GPU/CPU within a script.
\subsubsection{ASI}
\paragraph{\python{hotspice.ASI}: predefined ASI lattices}
This module provides two abstract classes from which all ASIs should inherit: \python{hotspice.ASI.IP_ASI} or \python{hotspice.ASI.OOP_ASI}.
Various lattices are available, as previously shown in~\cref{fig:2:ASIs}.
These all follow the same pattern: \python{hotspice.ASI.<ASI_name>(a, n, **kwargs)}, with two positional arguments.
The first argument is the lattice parameter, as defined by the red indicator in \cref{fig:2:ASIs}.
The second argument is the size of the underlying grid (one can also specify \python{nx} and \python{ny} separately).
For the predefined lattices in the \python{hotspice.ASI} module, these two parameters are enough information to create a rudimentary ASI.
\paragraph{Energies}\label{sec:2:API_energies}
Three predefined energy contributions are provided in the \python{hotspice.energies} module, though they can be accessed from the main \python{hotspice} namespace because they are used so often.
The magnetostatic interaction is implemented by the \python{hotspice.DipolarEnergy} or \python{hotspice.DiMonopolarEnergy} classes, with the latter using the monopole approximation to calculate the interaction.
By default, an ASI object takes only the \python{hotspice.DipolarEnergy} into account.
When relevant, the user has to explicitly add a \python{ZeemanEnergy} or \python{ExchangeEnergy}.
It is possible to set longer-range exchange interactions (next-nearest neighbour etc.) by manually setting the \python{local_interaction} field of an \python{ExchangeEnergy} object.
% TODO: create a custom "API" environment that we can put near all the different parts of the model to show code outside the main text?
\subsubsection{RC} % io and experiments modules
\subsubsection{Utilities} % Explain utils module (but only those functions/classes relevant to users) and perhaps mention the existence of plottools
\paragraph{GUI}
A graphical user interface (GUI) is available for \hotspice, which allows the user to directly interact with the ASI and observe changes in realtime. It can be run by calling \python{hotspice.gui.show(mm)}, with \python{mm} the ASI object, resulting in the window shown in~\cref{fig:2:GUI}.

\xfig[1.0]{2_Hotspice/GUI.png}{
	\label{fig:2:GUI}The \hotspice graphical user interface. This example shows a pinwheel ASI.
}

The state of the ASI is prominently displayed, and the bottom left panel shows a few useful statistics such as the elapsed time. The ASI display is controlled by the central bottom panel, which changes between 4 display modes.
By default, the magnetisation is shown as an averaged field, with the averaging method determined by the ASI lattice.
The second mode displays individual arrows, which either show each magnet's magnetisation direction or the effective field $\vc{H}_\mathrm{eff}$ it experiences. % Q: is it H? I wrote H because it does not add the magnetic moment. On a similar note, should we write B_ext or H_ext in the definition of the Zeeman energy?
In the third mode, the energy contributions ($E_\mathrm{MC}$, $E_\mathrm{Z}$, $E_\mathrm{Exch}$ and their sum $E_i$) and the resulting effective energy barrier $\EBtilde$ for each magnet can be shown, both along the easy and hard axis.
The last option is to show the spatial distribution (i.e., the value for each magnet) of some parameters like the temperature $T$, shape anisotropy $\EB$ and size of the magnetic moment $\mu$. \par
Buttons in the sidebar on the right allow the user to interact with the ASI by progressing through time, setting an initial state, or -- for more complex simulations -- apply custom functions.
By clicking with the mouse on the ASI plot, it is also possible to interact with the ASI at a granular level, switching one or multiple magnets. Finally, the red box in the bottom right controls the update algorithm.

\subsection{Advantages and disadvantages of the \hotspice approach} % Hindsight is 20/20
\subsubsection{Grid}
\subsubsection{Input/output RC}

\section{Verification} % See paper
\subsection{Hexagon}
\subsection{Non-interacting spin ensemble}
\subsection{Exchange-coupled OOP square system}
\subsubsection{Critical slowing down}
\subsection{Exchange- and magnetostatically-coupled OOP square system}
\subsection{Square-to-pinwheel transition angle}
